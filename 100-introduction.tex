\chapter{Introduction}

The $ \lambda $-calculus is an abstract tool that is used in an area where mathematics meets computer science, to study algorithms, programming languages and even category theory. It was conceived by Alonzo Church, primarily as a foundation for mathematics instead of set theory or type theory \autocite{church-lambda-calculus}. A couple of years later, Church used it to show that the `Entscheidungsproblem' was unsolvable: the problem asked for an algorithm that could tell about any mathematical statement whether it was true or false, and Church showed that such an algorithm could not exist \autocite{church-number-theory}. A year later, Alan Turing showed, using previous work of Kleene \autocite{kleene-lambda}, that an algorithm is definable using the $ \lambda $-calculus if and only if it is definable using a Turing machine \autocite{turing-lambda}, solidifying the position of both the $ \lambda $-calculus and Turing machines as abstract models for algorithmic computation.

Later, all kinds of different flavours and extensions of the $ \lambda $-calculus were put forth, with colorful names like `simply typed $ \lambda $-calculus', `System T' and `PCF'. Even though the $ \lambda $-calculus was originally a very abstract tool, it was also the inspiration for function programming languages, and traces of it can be seen in imperative programming languages, where unnamed functions are commonly called `lambda expressions' \autocite{java-lambdas} and are sometimes even written like \texttt{lambda x y : (x - y) * (x + y)} \autocite{python-expressions}.

Even so, the theoretical study of the $ \lambda $-calculus and its extensions continues to this day. For example, in 2017\footnote{Note that the paper has been around since 2012, when it was first published as a preprint on arXiv.}, a paper by Martin Hyland was published, named `classical lambda calculus in modern dress' \autocite{Hyland}. In this paper, Hyland approaches the $ \lambda $-calculus from the viewpoint of universal algebra, using algebraic theories, and more generally category theory, to study it. This way, he obtains two new proofs for old theorems. The paper also contains a new theorem that shows that two different ways to study the $ \lambda $-calculus using universal algebra are equivalent.

Now, in the last century, mathematics has changed a lot. Of course, new theorems have been proved, new conjectures have been made and new areas of mathematics have come into existence. However, as in many professions, the arrival of the computer has affected the way that work is done. All kinds of tools have been created that aid mathematicians in their job. Some of these tools help with quick calculations, for formulating or disproving new conjectures. Other tools help in structurally verifying ideas. There even have been some `proofs by computer', which consists of a proof on paper that the theorem can be reduced to a finite, but very large, computation, and a computer program that then executes this computation. For example, the first proofs of the four color theorem \autocite{four-color-theorem} or the Kepler conjecture \autocite{Kepler-conjecture} were done this way.

However, because the computation part of such a proof involves a lot of code, and computer code tends to contain bugs, accepting a proof by computer involves a certain amount of trust. Therefore, both of the theorems mentioned have subsequently also been proved using `computer proof assistants'\autocite{formalized-four-color-theorem}\autocite{formalized-Kepler-conjecture}. Such proof assistants, like `rocq', `lean' and `Agda', are computer programs with only a very small `trusted codebase'\footnote{Trusted codebase means the part of the codebase of which we hope that it is correct. The rest of the codebase is checked using this trusted core, so if the trusted core is correct, the rest is too.}, that can verify mathematical reasoning. In this way, if we trust the small core of such a proof assistant, and the proof assistant says that a proof is correct, then we can trust that indeed, the proof is correct.

However, the way that these programs reason about mathematics is very formal and rigid. This means that `formalizing', proving something using a proof assistant, usually involves a great amount of effort, usually much more than doing a pen-and-paper proof. However, talking about a choice between doing pen-and-paper proofs and working with proof assistants would be too simplistic. Often, doing a pen-and-paper proof can help one to develop an intuition and get new ideas, whereas formalizing those can then help to get a better view of the intricacies of a proof and to sharpen the understanding of why the proof works. Therefore, there is a lot of ongoing research into tools and best practices to make the process of formalizing as smooth as possible; to make these programs, which sometimes are experienced as `proof obstructors', really into `proof assistants'.

% <Under construction>

[Univalent foundations]
, a foundation of mathematics based on type theory set forth by Vladimir Voevodsky \autocite{voevodsky-univalent-foundations}.

In this thesis, we study Hyland's paper through the lens of univalent foundations. We work out the details of the proofs from the paper, see where subtleties arise when converting from set theory to univalent foundations and discuss the formalization of part of the material in the proof assistant `rocq'.

The major contributions of this thesis are
\begin{itemize}
  \item An analysis of the Karoubi envelope in Univalent foundations.
  \item Of particular interest is the discussion of Hyland's proof of the relative cartesian closedness of a category of retracts (or Karoubi envelope) in Section \ref{sec:relatively-cartesian-closed}, which was proved earlier by Paul Taylor in a different way. It turns out that in the translation from set theory to univalent foundations, the definition of the category of retracts `branches' into two nonequivalent definitions, and that Taylor's proof is about one definition, whereas Hyland's proof is about the other.
  \item Analysis of Hyland's work in it's historical context
  \item Alternative proof of the fundamental theorem
  \item Formalization
\end{itemize}
% </Under construction>

% 600-paper.tex
Now, most of this thesis works towards Chapter \ref{ch:the-paper}, about Hyland's paper.
% 500-previous-work.tex
He builds upon work of other authors, though, and understanding their work, exposited in Chapter \ref{ch:previous-work}, helps to understand Hyland's paper.
% 200-category-theory.tex
Since both Hyland and the other authors use a lot of category theory, Chapter \ref{ch:category-theory} establishes most of the preliminary knowledge regarding category theory. It is probably wise to skim this chapter, and sporadically come back to it to better understand the material in the other chapters.
% 300-univalent-foundations.tex
Because this thesis works from a univalent point of view, Chapter \ref{ch:univalent-foundations} introduces univalent foundations and builds the preliminary knowledge in that area for the rest of the paper.
% 400-algebraic-structures.tex
Then, Chapter \ref{ch:algebraic-structures} introduces the main objects that are studied by Hyland, namely $ \lambda $-theories and $ \Lambda $-algebras, together with related notions and examples.
% 700-formalization.tex
Lastly, the formalization of part of the material is discussed in Chapter \ref{ch:the-formalization}.

Note that throughout this document, links are included to \href{https://arnoudvanderleer.github.io/cs-masters-thesis/toc.html}{\nolinkurl{documentation}} of the corresponding formalized material. The documentation refers to the state of \href{https://github.com/UniMath/UniMath/tree/5eb5c8958c4dddd4219f895bf7bc51547395522d}{\texttt{the UniMath repository}} at commit \texttt{5eb5c8958c4dddd4219f895bf7bc51547395522d}.
