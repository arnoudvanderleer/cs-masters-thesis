\chapter{Previous work in categorical semantics}

% \begin{tabular}{|c|c|c|}\hline
%   $ K $ & $ \lambda xy.x $ & constant \\\hline
%   $ S $ & $ \lambda xyz.xz(yz) $ & \\\hline
%   $ I $ & $ \lambda x.x = SKK $ & identity \\\hline
%   $ Y $ & $ \lambda f.(\lambda x.f (xx))(\lambda x.f (xx)) $ & ﬁxpoint \\\hline
%   $ \bot $ & $ (\lambda x.xx)(\lambda x.xx) = (SII)(SII) = YI $ & bottom \\\hline
%   $ P $ & $ \lambda f gx.g(f x) = S(K(S(S(KS)K)))K $ & composition \\\hline
%   $ Q $ & $ \lambda f gax.ga(f ax) $ & ﬁbred composition \\\hline
%   $ \langle \rangle $ & $ \lambda xyz.zxy $ & pairing \\\hline
%   $ 0 $ & $ \lambda xy.x = K $ & left projection \\\hline
%   $ 1 $ & $ \lambda xy.y = KI $ & right projection \\\hline
% \end{tabular}

\section{The correspondence between categories and typed \texorpdfstring{$ \lambda $}{lambda}-calculi}\label{sec:lambek-correspondence}
In \cite{curry}, page 413, Scott and Lambek argue that there is a correspondence between simply typed $ \lambda $-calculi and cartesian closed categories (categories with products and `function objects').

Types in the $ \lambda $-calculus correspond to objects in the category.

Types $ A \to B $ in the $ \lambda $-calculus correspond to exponential objects $ B^A $ in the category.

Terms in the $ \lambda $-calculus of type $ B $, with free variables $ x_1: A_1, \dots, x_n: A_n $, correspond to morphisms $ A_1 \times \dots \times A_n \to B $.

A free variable $ x_i: A_i $ in a context with free variables $ x_1: A_1, \dots, x_n: A_n $ corresponds to the projection morphism $ \pi_i : A_1 \times \dots \times A_n \to A_i $.

Given a term $ s: B_1 \to B_2 $ and a term $ t: B_1 $, both with free variables $ x_1: A_1, \dots, x_n: A_n $, corresponding to morphisms $ \overline s: A_1 \times \dots \times A_n \to B_2 $ and $ \overline t: A_1 \times \dots \times A_n \to B_1 $, the application $ st: B_2 $ corresponds to the composite of the product morphism with the evaluation morphism $ A_1 \times \dots \times A_n \to B_2^{B_1} \times B_1 \to B_2 $.
\begin{center}
  \begin{tikzcd}
    & A_1 \times \dots \times A_n \arrow[ld, "\overline s"'] \arrow[rd, "\overline t"] \arrow[d, "{\langle \overline s, \overline t \rangle}", dashed] &\\
    B_2^{B_1} & B_2^{B_1} \times B_1 \arrow[l, "\pi_1"] \arrow[r, "\pi_2"'] \arrow[d, "ev"] & B_1\\
    & B_2 &
  \end{tikzcd}
\end{center}

Given a term $ t: B $ with free variables $ x_1: A_1, \dots, x_n: A_n $, the abstraction $ (\lambda x_n, t): A_n \to B $ corresponds to using the adjunction corresponding to the exponential object of $ A_n $:
\[ C(A_1 \times \dots \times A_{n-1} \times A_n, B) \simeq C(A_1 \times \dots \times A_{n-1}, B^{A_n}). \]

\section{The category of retracts}\label{sec:retracts-category}

The next sections make extensive use of a category called $ \R $, which Hyland calls the `category of retracts'. In this section, we will define the category, and show some properties about it.

Let $ L $ be a $ \lambda $-theory. First of all, for $ a_1, a_2: L_0 $, we define
\begin{align*}
  a_1 \circ a_2 &= \lambda x_1, a_1 (a_2 x_1);\\
  (a_1, a_2) &= \lambda x_1, x_1 a_1 a_2;\\
  \langle a_1, a_2 \rangle &= \lambda x_1, (a_1 x_1, a_2 x_1);\\
  \pi_i &= \lambda x_1, x_1 (\lambda x_2 x_3, x_{i + 1}).
\end{align*}
Although, actually, since every one of these starts with a $ \lambda $-abstraction, we need to lift the constants $ a_i $ to $ \iota_{0, 1}(a_i): L_1 $ to make the definitions above typecheck.

Note that $ \pi_i (a_1, a_2) = a_i $ and $ \pi_i \circ \langle a_1, a_2 \rangle = \lambda x_1, a_i x_1 $, which is exactly what we would expect of a projection.

Also, note that by replacing the $ x_i $ by $ x_{n + i} $ and the $ \iota_{0, 1}(a_i) $ by $ \iota_{n, 1}(a_i) $, we obtain definitions not only for elements of $ L_0 $, but for all $ L_n $.

\begin{definition}
  We define the category \index{R}$ \R $ as the Karoubi envelope of the monoid of the $ \lambda $-terms without free variables under composition. That is, the category of idempotent functions:
  \[ \R_0 = \{ A : L_0 \mid A \circ A = A \} \quad \text{and} \quad \R(A, B) = \{ f: L_0 \mid B \circ f \circ A = f \}, \]
  with $ \id A = A $ and composition given by $ \circ $.
\end{definition}

\begin{remark}
  Hyland instead defines $ \R $ as
  \[ \R_0 = \{ A : L_1 \mid A \bullet A = A \} \quad \text{and} \quad \R(A, B) = \{ f : L_1 \mid B \bullet f \bullet A = f \}, \]
  writing $ s \bullet t $ instead of $ s \bullet (t) $ for $ s, t : L_1 $. Note that the following diagram commutes:
  \begin{center}
    \begin{tikzcd}
      L_1 \times L_1 \arrow[r, "\bullet"] \arrow[d, "{(s, t) \mapsto ((\lambda x_1, s), (\lambda x_1, t))}"'] & L_1 \arrow[d, "{s \mapsto (\lambda x_1, s)}"]\\
      L_0 \times L_0 \arrow[r, "\circ"] & L_0
    \end{tikzcd}
  \end{center}
  Now, since for $ A : \R $, $ A = \lambda x_1, \iota_{0, 1}(A) (\iota_{0, 1}(A) x_1) $, we have $ \lambda x_1, \iota_{0, 1}(A) x_1 = A $. This shows that $ s \mapsto \lambda x_1, s $ and $ t \mapsto \iota_{0, 1}(t) x_1 $ (both on objects and morphisms) constitute an equivalence between Hyland's category of retracts and Scott's category of retracts.
\end{remark}

Now, to give a bit more intuition for the objects of $ \R $, we can pretend that an object $ A : \R $ consists of the set of elements that satisfy $ A a = a $. Then a morphism $ f : \R(A, B) $ gives $ B (f a) = (B \circ f) a = f a $. This actually constitutes a functor from $ R $ to $ \Pshf L $:

\begin{definition}\label{def:retracts-embedding}
  We define a functor $ \varphi: \R \to \Pshf L $ by taking
  \[ \varphi(A)_n = \{ a : L_n \mid \iota_{0, n}(A) a = a \} \quad \text{and} \quad \varphi(f)_n(a) = \iota_{0, n}(f) a \]
  for $ A, B : \R $, $ f: \R(A, B) $ and $ a : A $. The presheaf action on $ \varphi(A) $ is given by the substitution of $ L $:
  \[ (a, f) \mapsto a \bullet f \]
  for $ f : L_n^m $ and $ a : L_m $ such that $ \iota_{0, m}(A) a = a $.
\end{definition}

It turns out that this embeds $ \R $ as a full subcategory of $ \Pshf L $:
\begin{lemma}
  This functor $ \varphi $ is fully faithful.
\end{lemma}
\begin{proof}
  Take $ A, B : \R $. We need to show that $ f \mapsto \varphi(f) $ is an equivalence between $ \R(A, B) $ and $ \Pshf L(\varphi(A), \varphi(B)) $. We have a function
  \[ \psi: \Pshf L(\varphi(A), \varphi(B)) \to \R(A, B), \quad g \mapsto (\lambda x_1, g_1(\iota_1(A) x_1)) \]
  which gives us the inverse. To see that this even typechecks, note that we have
  \[ \iota_1(A) x_1 : \varphi(A)_1 \quad \text{and} \quad g_1(\iota_1(A) x_1) : \varphi(B)_1 \subseteq L_1. \]
  Using the fact that $ g $ is a presheaf morphism, we can show that
  \[ B \circ \psi(g) \circ A = \psi(g), \]
  and that $ \varphi $ and $ \psi $ are inverses.
\end{proof}

\begin{remark}
  Note that for all $ A : \R $, we can `reduce' any $ x: L_n $ to
  \[ \iota_{0, n}(A) x : \varphi(A)_n \]
  and in the same way, for all $ A, B: \R $, we can turn any $ f: L_0 $ into a morphism $ B \circ f \circ A : \R(A, B) $. In particular, we have $ B \circ A : \R(A, B) $.
  Of course, all elements of $ \varphi(A)_n $ and all elements of $ \R(A, B) $ arise this way.
\end{remark}

\begin{remark}
  Note that if $ L $ is a nontrivial $ \lambda $-theory, $ \R $ is not a univalent category. To see this, note, for example, that we have an object $ X := \langle \pi_1, \pi_2 \rangle : \R $ (corresponding to the type of `pairs' of $ \lambda $-terms). Since $ L_0 $ is a set, $ X = X $ is a proposition. However, $ X $ has (at least) two automorphisms:
  \[ \langle \pi_1, \pi_2 \rangle \quad \text{and} \quad \langle \pi_2, \pi_1 \rangle. \]
  These are the identity, and the automorphism (of order 2) that swaps the elements of the pair. To see that these are indeed different morphisms, note that applying them (or their lifted versions) to $ (x_{2, 1}, x_{2, 2}) $ gives respectively $ x_{2, 1} $ and $ x_{2, 2} $, which are distinct elements by Lemma \ref{lem:nontrivial-algebraic-theory}.
\end{remark}

In the next chapter, the `universal object' $ U : \R $, given by the identity $ \lambda x_1, x_1 $, plays a major role. Note that for all $ A: \R $, we have morphisms $ A: \R(U, A) $ and $ A: \R(A, U) $, which exhibit $ A $ as a retract of $ U $. Also note that $ \varphi(U) = L $.

Note that $ \R $ has many (isomorphic, but not equal for nontrivial $ L $) terminal objects, given by $ I_c := \lambda x_1, \iota_{0, 1}(c) : \R $ for any $ c: L_0 $. These are terminal because for $ f: A \to I_c $, we have $ f = I_c \circ f = I_c $. Note that $ \varphi(I_c)_n = \{ \iota_{0, n}(c) \} $. We will choose $ I = \lambda x_1 x_2, x_2 : \R $ as our main example of the terminal object.

We might wonder whether $ \R $ also has an initial object $ O $. However, for any $ c: L_0 $, we would have a constant morphism
\[ I_c = \lambda x_1, \iota_{0, 1}(c) : \R(O, U), \]
so if $ L $ is nontrivial, $ \R $ has no initial object.

$ \R $ has binary products with projections and product morphisms
\[ A_1 \times A_2 = \langle p_1, p_2 \rangle, \quad p_i = A_i \circ \pi_i \quad \text{and} \quad \langle f, g \rangle. \]
Recall that for any object $ A $, we have $ A = \id A $, which for $ A_1 \times A_2 $ is $ \langle p_1, p_2 \rangle $ by the universal property of the product, which explains why the product is of this form.

$ \R $ also has exponential objects
\[ C^B = \lambda x_1, C \circ x_1 \circ B \]
with evaluation morphism $ \epsilon_{BC}: C^B \times B \to C $ given by
\[ \epsilon_{BC} = \lambda x_1, C(\pi_1 x_1 (B (\pi_2 x_1))), \]
which is universal because we can lift a morphism $ f: \R(A \times B, C) $ to a morphism $ \psi(f): \R(A, C^B) $ given by
\[ \psi(f) = \lambda x_1 x_2, f (x_1, x_2). \]
Note that for $ g: \R(A, C^B) $, the inverse $ \psi^{-1}(g) $ is given by
\[ \epsilon \circ \langle g \circ \pi_1, B \circ \pi_2 \rangle = \lambda x_1, g (\pi_1 x_1) (\pi_2 x_1): \R(A \times B, C). \]
Also note that
\[ \psi(\epsilon_{BC}) = \lambda x_1, C \circ x_1 \circ B = C^B = \id{C^B}. \]
Note that $ \varphi(C^B)_0 = \R(B, C) $, as we would expect.

Now, we might wonder whether there exists some $ A: \R $ such that $ \varphi(A)_0 = \emptyset $. However, for any $ c : L_0 $, we have $ A c : \varphi(A)_0 $, because
\[ A c = (A \circ A) c = A (A c). \]
Note that we can lift constants from $ \varphi(A)_0 $ to any $ \varphi(A)_n $, so they are all nonempty.

Combining this with the embedding of $ \R \hookrightarrow \Pshf L $, we would expect $ \R $ to not have all pullbacks. This is because in $ \Pshf L $, for a cospan $ B \xrightarrow f A \xleftarrow g C $ with $ f_n(B_n) \cap g_n(C_n) = \emptyset $ for some $ n $, the pullback $ Q $ would have $ Q_n = \emptyset $, which could never happen with an object coming from $ \R $. Note, however, that this can not be made rigorous, because a fully faithful embedding reflects limits, but does not necessarily preserve them.

However, it is true that $ \R $ does not have all pullbacks (if $ L $ is nontrivial). Consider for example the following cospan:
\[ I \xrightarrow f U \xleftarrow g I \]
for different $ f, g: \R(I, U) $. For example, $ f = (\lambda x_1, \iota_{0, 1}(\pi_1)) $ and $ g = (\lambda x_1, \iota_{0, 1}(\pi_2)) $. Now, take any object $ Q: \R $. Note that we have a unique morphism $ I: \R(Q, I) $. Then we have the following diagram:
\begin{center}
  \begin{tikzcd}
    Q \arrow[r, "I"] \arrow[d, "I"] & I \arrow[d, "g"]\\
    I \arrow[r, "f"] & U
  \end{tikzcd}
\end{center}
with
\[ f \circ I = f \not = g = g \circ I, \]
so the diagram does not commute, and $ Q $ is not a pullback of this cospan.

Taylor notes (\cite{taylor}, Section 1.5) that the objects in $ \R $ have very strong properties with respect to fixpoints. One of the properties also arises via Lawvere's fixed point theorem (\cite{lawvere-fixpoints}, page 136): For all $ B: \R $, since $ B^U $ is a retract of $ U $, every endomorphism $ f: B \to B $ has a fixpoint. That is, there exists $ s: I \to B $ such that $ f \circ s = s $. Working out the proof even yields an explicit term:
\[ s = \lambda i, (\lambda x, f (x x)) (\lambda x, f (x x)). \]
Indeed, $ s = \lambda i, f ((\lambda x, f (x x)) (\lambda x, f (x x))) = f \circ s $, and $ B \circ s = B \circ f \circ s = s = s \circ I $, so $ s : \R(I, B) $.

From this, Taylor deduces (\cite{taylor}, \S 1.5.12) that $ \R $ does not have all coproducts if $ L $ is nontrivial, because suppose that $ \R $ has all coproducts. Then $ B = I + I $ is a `boolean algebra object': We define $ \bot, \top: I \to B $ to be the injections on the left and right components. Since $ \R $ is cartesian closed, binary products distribute over binary coproducts, so we have $ B \times B \cong ((I \times I) + (I \times I)) + ((I \times I) + (I \times I)) $, and note that $ I \times I \cong I $. Using the universal property of the coproduct, we can define $ \lnot: B \to B $ componentwise as $ \lnot = [\top, \bot] $, the coproduct arrow
\begin{center}
  \begin{tikzcd}[row sep = .3in]
    I \arrow[r, "\bot"] \arrow[rd, "\top"'] & I + I \arrow[d, dashed, "{[\top, \bot]}"description] & I \arrow[l, "\top"'] \arrow[ld, "\bot"]\\
    & I + I &
  \end{tikzcd}
  % \begin{tikzcd}[row sep = .3in]
  %   I \arrow[rrrd, "\bot"'] \arrow[r, "\bot"] & I + I \arrow[rrd, "{[\bot, \bot]}" description, dashed] \arrow[rr, bend left] & I \arrow[rd, "\bot"] \arrow[l, "\top"'] & I + I + I + I \arrow[d, dashed, "{[[\bot, \bot], [\bot, \top]]}" description] & I \arrow[ld, "\bot"'] \arrow[r, "\bot"] & I + I \arrow[lld, "{[\bot, \top]}" description, dashed] \arrow[ll, bend right] & I \arrow[llld, "\top"] \arrow[l, "\top"'] \\
  %   & & & I + I & & &
  % \end{tikzcd}
\end{center}
Note that by the definition of $ \lnot $, $ \lnot \circ \bot = \top $. Similarly, we define $ \land, \lor : B \times B \to B $ as $ \land = [[\bot, \bot], [\bot, \top]] $ and $ \lor = [[\bot, \top], [\top, \top]] $. Using the same universal property, we can also verify some properties of $ \bot, \top, \land $ and $ \lnot $, like the fact that the following diagrams commute:
\begin{center}
  \begin{tikzcd}[column sep = .5in]
    B \arrow[rd, "{\id B}"] \arrow[r, "{\langle \id B, \id B \rangle}"] & B \times B \arrow[d, "\land"]\\
    & B
  \end{tikzcd}
  \begin{tikzcd}[column sep = .5in]
    B \arrow[d, "!"] \arrow[r, "{\langle \lnot, \id B \rangle}"] & B \times B \arrow[d, "\land"]\\
    I \arrow[r, "\bot"] & B
  \end{tikzcd}
\end{center}
for $ !: B \to I $ the terminal projection. We do this by checking, for example, that $ \id B \circ \top = \land \circ \langle \id B, \id B \rangle \circ \top $ and $ \id B \circ \bot = \land \circ \langle \id B, \id B \rangle \circ \bot $. Now, as mentioned above, every endomorphism has a fixed point. In particular, we have some $ \star: I \to B $ such that $ \lnot \circ \star = \star $. Now, note that
\[ \star = \land \circ \langle \id B, \id B \rangle \circ \star = \land \circ \langle \star, \star \rangle = \land \circ \langle \star, \lnot \circ \star \rangle = \land \circ \langle \id B, \lnot \rangle \circ \star = \bot \circ ! \circ \star = \bot \]
and then
\[ \bot = \star = \lnot \circ \star = \lnot \circ \bot = \top. \]
Now, for any object $ A: \R $ and any two global elements $ f, g: I \to A $, we have the following diagram:
\begin{center}
  \begin{tikzcd}
    I \arrow[r, shift left, "\bot"] \arrow[r, shift right, "\top"'] \arrow[rr, bend left, "f"] \arrow[rr, bend right, "g"'] & I + I \arrow[r, "{[f, g]}"] & A
  \end{tikzcd}
\end{center}
and we have
\[ f = [f, g] \circ \bot = [f, g] \circ \top = g. \]
In particular, for any two objects $ A, A^\prime: \R $, since we have $ A \circ A^\prime : \R(A^\prime, A) $, so $ \R(A^\prime, A) $ is nonempty, we have
\[ \R(A^\prime, A) \simeq \R(I \times A^\prime, A) \simeq \R(I, A^{A^\prime}) \simeq \{ \star \}, \]
so $ \R $ is the trivial category and $ L $ is trivial.

\section{Scott's Representation Theorem}
The correspondence in Section \ref{sec:lambek-correspondence} between simply-typed $ \lambda $-calculi and cartesian closed categories raises a question whether such a correspondence also exists for untyped $ \lambda $-calculi. Definition \ref{def:endomorphism-theory} shows that in fairly general circumstances we can take one object $ c $ in a category $ C $ and consider the morphisms $ t: C(c^n, c) $ as terms in an untyped $ \lambda $-calculus. Hyland calls this the `endomorphism theory' of $ c $.

\begin{remark}
  To construct a \textit{simply typed} $ \lambda $-calculus from a category, we just need a cartesian closed category. In a simply typed $ \lambda $-calculus, there is a lot of restriction on which terms we can apply to each other. A term of type $ A \to B $ can only be applied to a term of type $ A $, which gives a term of type $ B $. In particular, a term can be applied only finitely many times to other terms, and every time, the result has a different type.

  On the other hand, for an \textit{untyped} $ \lambda $-calculus, we need a cartesian closed category with a `reflexive object'. This is because in the untyped $ \lambda $-calculus, we can apply arbitrary terms to each other. For example, we can apply the term $ (\lambda x_1, x_1 x_1) $ to itself, which would not be typable in the simply typed $ \lambda $-calculus. Suppose that we have a category $ C $ and an object $ U $ such that the morphisms $ C(U^n, U) $ give the untype $ \lambda $-terms in $ n $ free variables, for all $ n $. Now, given two terms $ f, g : C(U^n, U) $, for the application $ f g $, we need to consider $ f $ as a morphism in $ C(U^n, U^U) $. We can do this by postcomposing with a morphism $ \varphi: C(U, U^U) $. On the other hand, if $ n > 0 $, then $ (\lambda x_n, f) $ is a morphism in $ C(U^{n - 1}, U^U) $, but it is a term in $ n - 1 $ free variables, so it should be in $ C(U^{n - 1}, U) $. For this, we postcompose with a morphism $ \psi: C(U^U, U) $. Now, for our untyped $ \lambda $-calculus to have $ \beta $-equality, we need $ \psi \cdot \varphi = \id{U^U} $, which means that the exponential $ U^U $ of $ U $ is a retract of $ U $. This is exactly what it means for $ U $ to be a \iindex{reflexive object}: an object $ U $ in a cartesian closed category, that has a retraction onto its `function space' $ U^U $. Note that if we want our $ \lambda $-theory to also have $ \eta $-equality, the retraction must be an isomorphism.

  Note that $ \SET $ is a cartesian closed category, but that for sets $ X $ and $ Y $, the function space $ X^Y $ has cardinality $ \vert X \vert^{\vert Y \vert} $, and therefore $ U^U $ cannot be a retract of $ U $, unless $ U = \{ \star \} $, in which case we have a very trivial $ \lambda $-calculus: $ \SET(U^n, U) = \{ \star \} $.

  During the 1960s, computer scientists sought for nontrivial examples of reflexive objects, there is a quote by Dana Scott that ``Lambda-calculus has no mathematical models!''\cite{strachey}. However, in 1969, the same Dana Scott discovered that the category of (continuous) lattices with (Scott-)continuous functions between them has a nontrivial reflexive object, with the retraction onto the function spaces being even an isomorphism. Such a reflexive object $ D_\infty $ is obtained by starting with an arbitrary lattice $ D_0 $, iteratively taking $ D_{n + 1} = D_n^{D_n} $, with a retraction (in the `wrong' direction) $ r: D_n^{D_n} \to D_n $, and then passing to the limit $ D_\infty = \lim_{\leftarrow} D_n $ (for the main result, see Theorem 4.4 in \cite{scott-continuous}, page 127).
\end{remark}

Since Lambek showed an equivalence between simply typed $ \lambda $-calculi and cartesian closed categories, and since we have a construction for an untyped $ \lambda $-calculus from a cartesian closed category with a reflexive object, we can wonder whether this construction constitutes contitutes an equivalence between untyped $ \lambda $-calculi and some class of categories. This question finds a partial answer in the following theorem, originally proven in a very syntactical way by Dana Scott (see \cite{curry}, page 418).
\begin{theorem}
  We can obtain every untyped $ \lambda $-calculus as the endomorphism theory of some object in some category.
\end{theorem}
\begin{proof}
  Let $ L $ be a $ \lambda $-theory. Scott considers its category of retracts $ \R $, with `universal object' $ U $.

  Note that $ U^U $ is a retract of $ U $, so $ U $ is a reflexive object.

  Therefore, $ E(U) $, the endomorphism theory of $ U $, has a $ \lambda $-theory structure. Note that the finite powers of $ U $ in $ \R $ are given by $ U^0 = I $ and $ U^{n + 1} = U^n \times U $.

  We have $ E(U)_n = \R(U^n, U) = \{ f: L_0 \mid U \circ f \circ U^n = f \} $. The variables of $ E(U) $ are the projections of $ U^n $:
  \[ q_{n, i} = \pi_2 \circ \underbrace{\pi_1 \circ \dots \circ \pi_1}_{n - i}. \]
  The substitution is given by composition with the product morphism:
  \[ f \bullet g = f \circ \langle \langle \langle I, g_1 \rangle, \dots \rangle, g_n \rangle. \]
  We have $ U^U = \lambda f, U \circ f \circ U = \lambda x_1 x_2, x_1 x_2 $. Using the equivalence $ \R(U^n \times U, U) \simeq \R(U^n, U^U) $ and the retraction $ U^U: U \to U^U $, the abstraction and application $ \lambda $ and $ \rho $ are given by
  \[ \lambda(f) = \lambda x_1 x_2, \iota_{0, 2}(f)(x_1, x_2), \quad \rho(g) = \lambda x_1, \iota_{0, 1}(g) (\pi_1 x_1) (\pi_2 x_1). \]
  for $ f: \R(U^{n + 1}, U) $ and $ g: \R(U^n, U) $.

  Now, we have bijections $ \psi_0: E(U)_0 \xrightarrow{\sim} L_0 $, given by
  \[ \psi_0(f) = f (\lambda x_1, x_1) \quad \text{and} \quad \psi_0^{-1}(g) = \lambda x_1, \iota_{0, 1}(g). \]
  We can extend this to any $ n $, by reducing any term to a constant by repeatedly using $ \lambda $, then applying the bijection, and then lifting it again using $ \rho $. Explicitly, we obtain
  \[ \psi_n(f) = \iota_{0, n}(f) ((((\lambda x_{n+1}, x_{n+1}), x_1), \dots), x_n), \quad \text{and} \quad \psi^{-1}_n(g) = \lambda x_1, g \bullet (q_i x_1)_i. \]
  It is not hard to verify that this is indeed a bijection, using at one point the fact that $ f: \R(U^n, U) $ is defined by $ f \circ U^n = f $, for
  \[ U^n = \lambda x_1, (((\lambda x_2, x_2), q_{n, 1} x_1 ), \dots, q_{n, n} x_1 ). \]
  It is also pretty straightforward to check that
  \begin{align*}
    \psi(q_{n, i}) &= x_i, & \psi(f) \bullet (\psi(g_i))_i &= \psi(f \bullet g),\\
    \psi(\lambda(h)) &= \lambda(\psi(h)), & \psi(\rho(h^\prime)) &= \rho(\psi(h^\prime))
  \end{align*}
  for $ f: E(U)_m $, $ g: E(U)_n^m $, $ h: E(U)_{n + 1} $ and $ h^\prime : E(U)_n $. Therefore, $ \psi $ is an isomorphism of $ \lambda $-theories.
\end{proof}

\section{The Taylor Fibration}

In his dissertation, Paul Taylor shows that $ \R $ is not only cartesian closed, but also \iindex{relatively cartesian closed}.

In Section \ref{sec:dependent-products}, we studied internal and external representations of families of objects in a category and how they behaved under substitutions (pullbacks). This was to arrive at a definition for dependent products and sums, as the right and left adjoints to the pullback (or substitution) functor $ \alpha^*: (C \downarrow A) \to (C \downarrow B) $ along some morphism $ \alpha : C(B, A) $.

Now, some categories are not locally cartesian closed. That is: not all pullback/substitution functors $ \alpha^* $ exist or have a right adjoint. For example, $ \R $ does not have all pullbacks, so the substitution functors do not always exist. In such a category $ C $, the functor $ C^2 \to C $ is not a fibration. One way to look at this, is that in such a category not every morphism $ X \to A $ represents a family of objects. In such a category, we can carefully choose a subset of the morphisms to represent our indexed families. We will call a morphism that we choose to represent an indexed family a \iindex{display map}. In most cases, we have quite a bit of choice how big we want our subtype of display maps to be. However, to make sure that indexed families are well-behaved, the subtype of display maps needs to have some properties:
\begin{enumerate}
  \item The pullback of a display map along any morphism exists and is a display map.
  \item The composite of two display maps is a display map.
  \item $ C $ has a terminal object and any terminal projection is a display map.
\end{enumerate}
\begin{remark}
  A `maximal' example of a subtype of display maps is, for example, in the category $ \SET $, where we can take our subtype of display maps to equal the full type of all morphisms of $ C $.
\end{remark}
\begin{remark}
  A `minimal' example of a subtype of display maps is the subtype of (maps isomorphic to) product projections in a category with finite products. In this case, all indexed families are constant, and then dependent sums and products become binary products and exponential objects.
\end{remark}

Now, let $ C $ be a category with a subtype of display maps $ D \subseteq C $. We will denote the subtype of display maps from $ X $ to $ A $ with $ D(X, A) \subseteq C(X, A) $. For any $ A : C $, we define the category $ (C \downarrow_D A) $ as a full subcategory of the slice category $ (C \downarrow A) $, with as objects the display maps $ f: D(X, A) $. The morphisms between two objects of $ (C \downarrow_D A) $ are still all the morphisms of $ (C \downarrow A) $ (i.e. the morphisms of $ C $ that commute with the display maps).

Note that for the terminal object $ I : C $, $ (C \downarrow_D I) $ is still equivalent to $ C $, since every terminal projection is a display map.

Also note that since the pullback of display maps against any map exist (and are display maps again), we get a pullback functor $ \alpha^*: (C \downarrow_D A) \to (C \downarrow_D B) $. This is the restriction of the pullback functor $ \alpha^*: (C \downarrow A) \to (C \downarrow B) $, if it exists.

Note that since composing two display maps gives a display map again, and since the dependent sum is given by postcomposition, $ \alpha^* $ has a left adjoint for all display maps $ \alpha $. That is: the fiber categories $ (C \downarrow_D A) $ have dependent sums over display maps.

The question whether the fiber categories $ (C \downarrow_D A) $ also have dependent products over display maps, brings us to the definition of relative cartesian closedness.
\begin{definition}
  A category $ C $ is \index{cartesian closed!relatively}\textit{cartesian closed relative} to a class of display maps $ D $, if the substitution functors $ \alpha^* $ along display maps have right adjoints.
\end{definition}

Now, analogously to \ref{lem:locally-cartesian-closed}, Taylor shows:
\begin{lemma}
  If a category $ C $ is cartesian closed relative to a class of display maps $ D $, then the fiber categories $ (C \downarrow_D A) $ are cartesian closed and the substitution functors $ \alpha^* $ preserve this structure.
\end{lemma}
\begin{proof}
  Taylor proves this in a series of lemmas leading up to \S 4.3.7 in \cite{taylor}. It is also proved as Proposition 6 of \cite{theory-of-constructions}.
\end{proof}

\subsection{Taylor's proof}

As Hyland remarks, Taylor shows that $ \R $ is relatively cartesian closed using a very syntactical argument, in the spirit of Scott.

He starts out with a kind of `external' representation of indexed families $ (X_a)_a $ in $ \R $. He denotes these as `functions' $ A \to \R_0 $. They are the elements $ X: L_0 $ with
\[ X \circ A = X \quad \text{and} \quad (\lambda x_1, (X x_1) \circ (X x_1)) = X. \]
These $ X $ form a category $ \R^A $, with the morphisms in $ \R^A(X, Y) $ given by $ f: L_0 $ with $ f \circ A = f $ and $ (\lambda x_1, (Y x_1) \circ (f x_1) \circ (X x_1)) = f $. The identity on $ X $ is given by $ X $, and the composition is given by $ f \cdot g = \lambda x_1, g x_1 \circ f x_1 $.

Taylor shows that these categories $ \R^A $ are cartesian closed. He notes that assigning these categories $ \R^A $ to objects $ A: \R $ again constitutes a contravariant (pseudo)functor $ \op \R \to \Cat $, sending morphisms $ A \to B $ to precomposition functors $ \R^B \to \R^A $.

For $ A: \R $, we introduce the combinator
\[ \sum_A = \lambda x_1 x_2, (A (\pi_1 x_2), x_1 (\pi_1 x_2) (\pi_2 x_2)). \]

For $ A: \SET $, we have an equivalence between the elements of $ \SET^A $ and the elements of the fiber $ (\SET \downarrow A) $ of the fibration $ \SET^2 \to \SET $. Now, for $ A: \R $, $ \sum_A $ gives a functor from $ \R^A $ to $ (\R \downarrow A) $. Note that it sends objects $ X: \R^A $ to $ \sum_A X $, together with a projection morphism $ p_X = A \circ \pi_1: \sum_A X \to A $. Note that with the embedding in Definition \ref{def:retracts-embedding} into $ \Pshf L $, we can consider $ \sum_A X $ as consisting of pairs $ (a, x) $ with $ a : A $ and $ x : X a $, which is exactly what we would expect from a dependent sum.

Now, $ \sum_A $ is fully faithful: given a morphism $ g: \R\left(\sum_A X, \sum_A Y\right) $, we take
\[ \psi(g) = \lambda x_1 x_2, \pi_2 (g (x_1, x_2)). \]
For verifying that $ \psi(g) $ is indeed a morphism in $ \R^A(X, Y) $, it helps to recall that $ g \circ \sum_A X = g = \sum_A Y \circ g $ and $ p_Y \circ g = p_X $. Since $ \psi(\sum_A f) = f $ for all $ f: \R^A(X, Y) $ and $ \sum_A \psi(g) = g $ for all $ g: \R(\sum_A X, \sum_A Y) $, $ \sum_A $ is indeed fully faithful.

On the other hand, $ \sum_A $ is generally not surjective. However, we can choose our subtype $ D $ of display maps in such a way that the restriction $ \R^A \to (C \downarrow_D A) $ becomes essentially surjective.

\begin{definition}
  For $ \R $, we will consider a morphism $ f: X \to A $ to be a display map if we have some $ Y : \R^A $ like above, and some isomorphism $ g: (X, f) \xrightarrow{\sim} (\sum_A Y, p_Y) $ in $ (\R \downarrow A) $.
\end{definition}

\begin{remark}
  Hyland actually gives a different characterization of Taylor's display maps. He claims that Taylor takes the display maps $ X \to A $ to be the retracts in $ (\R \downarrow A) $ of $ p_1: A \times U \to A $,
  the projection onto the first coordinate. The two characterizations are equivalent:

  Given $ Y: \R^A $, intuitively $ Y a $ is a retract of $ U $ for all $ a $. Concretely, both morphisms $ r : A \times U \to \sum_A Y $ and $ s : \sum_A Y \to A \times U $ are given by $ \sum_A Y $ and these commute with the projection to $ A $. Therefore, if we have an isomorphism $ g: X \xrightarrow{\sim} \sum_A Y $ in $ (\R \downarrow A) $, then $ \sum_A Y \cdot g^{-1} $ and $ g \cdot \sum_A Y $ make $ X $ into a retract of $ A \times U $.

  Conversely, given a retraction $ r : A \times U \to X $ and section $ s : X \to A \times U $ in $ (\R \downarrow A) $, we have
  \[ Y = \lambda x_1 x_2, \pi_2 (s (r (x_1, x_2))) : \R^A. \]
  Using the properties of $ r $ and $ s $ and the definition of $ \sum_A Y $, one can show that $ r $ gives a morphism $ \sum_A Y \to X $ and $ s $ gives a morphism $ X \to \sum_A Y $, and that $ r \circ s = \id{\sum_A Y} $. Combined with the fact that $ s \circ r = \id X $, this shows that $ X $ is isomorphic to $ \sum_A Y $.
\end{remark}

\begin{remark}
  Recall that if $ L $ is nontrivial, $ \R $ is not univalent, and the existence of $ Y: \R^A $ with the isomorphism $ g: X \xrightarrow{\sim} \sum_A Y $ is not a proposition. Take, for example, $ Y : \R^I $ given by $ (\lambda x_1, U \times U) $. Recall that $ (\R \downarrow I) $ is equivalent to $ \R $. Under this equivalence $ \sum_I Y $ is equivalent to $ U \times U $. As mentioned before, $ \sum_I Y $ has (at least) two distinct isomorphisms to itself: the identity and the isomorphism that swaps both sides of the product.

  In a similar way, being a retract of $ A \times U $ is not a proposition. Therefore, if we want the class of display maps to really be a subclass of the class of morphisms, we need the existence of $ Y: \R^A $ and the isomorphism $ g : X \xrightarrow \sim \sum_A Y $, or the existence of the retraction $ A \times U \to X $, to mean \textit{mere existence} in this case. This means that we cannot use these in constructions, except for mere propositions.
\end{remark}

Taylor shows that these display maps indeed satisfy the three properties mentioned above. However, in univalent foundations, there are some subtleties in the case of pullbacks:
\begin{enumerate}
  \item Given a display map $ (X, f): (\R \downarrow_D A) $ and a morphism $ \alpha: \R(B, A) $. Recall that this means that there merely exists a $ Y: \R^A $ and an isomorphism $ X \xrightarrow \sim \sum_A Y $ in $ (\R \downarrow A) $. Therefore, we have mere existence of a pullback $ \sum_B (Y \circ \alpha) $ of $ \sum_A Y $ along $ \alpha $. For all $ C: \R $ with $ \beta: \R(C, B) $ and $ \gamma: \R(C, \sum_A Y) $ that make the square commute, we have the morphism $ \lambda x_1, (\beta x_1, \pi_2 (\gamma x_1)): \R(C, \sum_B (Y \circ \alpha)) $.
    \begin{center}
      \begin{tikzcd}[column sep = .5in]
        C \arrow[rrrd, bend left, "\gamma"] \arrow[dd, bend right=90, "\beta"'] \arrow[d, dashed, "{\lambda x_1, (\beta x_1, \pi_2 (\gamma x_1))}"] \\
        \sum_B (Y \circ \alpha) \arrow[rrr, "{\lambda x_1, (\alpha (\pi_1 x_1), Y (\alpha (\pi_1 x_1)) (\pi_2 x_1))}"] \arrow[d, "p_{(Y \circ \alpha)}"] &&& \sum_A Y \arrow[d, "p_Y"] & X \arrow[l, "g"] \arrow[ld, "f"]\\
        B \arrow[rrr, "\alpha"] &&& A
      \end{tikzcd}
    \end{center}
    By the isomorphism between $ X $ and $ \sum_A Y $, $ \sum_B (Y \circ \alpha) $ is also a pullback of $ X $: by postcomposing with $ g $ and its inverse, we see that morphisms from $ \sum_B (Y \circ A) $ and $ C $ to $ X $ are equivalent to morphisms to $ \sum_A Y $.
  \item Given display maps $ f: B \to A $ and $ g: C \to B $. We have $ X : \R^A $ and $ Y: \R^B $ with isomorphisms $ s: B \xrightarrow \sim \sum_A X $ and $ t: C \xrightarrow \sim \sum_B Y $. We need to show that $ f \circ g: C \to A $ is also a display map.
    \begin{center}
      \begin{tikzcd}
        C \arrow[d, "g"] \arrow[r, "\sim", "t"'] & \sum_B Y \arrow[ld, "p_Y"] \arrow[r, "u"', "\sim"] & \sum_A Z \arrow[ldld, bend left, "p_Z"]\\
        B \arrow[d, "f"] \arrow[r, "\sim", "s"'] & \sum_A X \arrow[ld, "p_X"]\\
        A
      \end{tikzcd}
    \end{center}
    Intuitively, $ \sum_B Y \cong \sum_A Z $ represents
    \[ \sum_{b: \sum_{a: A} X a} Y b \cong \sum_{a: A} \sum_{x: X a} Y(a, x), \]
    by the isomorphism that relates $ ((a, x), y) $ to $ (a, (x, y)) $. Therefore, consider
    \[ Z = \lambda x_1 x_2, (X x_1 (\pi_1 x_2), Y (s^{-1} (x_1, \pi_1 x_2)) (\pi_2 x_2)): \R^A. \]
    we have an isomorphism $ u: \sum_B Y \xrightarrow \sim \sum_A Z $ given by:
    \[ u = \lambda x_1, (A a, (X a x, Y b y)) \]
    with
    \[ b = \pi_1 x_1;\quad a = \pi_1 (s b); \quad x = \pi_2 (s b); \quad y = \pi_2 x_1, \]
    and
    \[ u^{-1} = \lambda x_1, (s^{-1}(A a, X a x), Y b y) \]
    with
    \[ a = \pi_1 x_1; \quad x = \pi_1 (\pi_2 x_1); \quad b = s^{-1}(a, x); \quad y = \pi_2 (\pi_2 x_1) \]
    and then $ u \circ t $ is an isomorphism in $ (\R \downarrow A) $ between $ (C, f \circ g) $ and $ (\sum_A Z, p_Z) $.

    % \TODO: Verify that
    % \begin{itemize}
    %   \item $ Z: \R^A $
    %     \begin{align*}
    %       &Z x_1 (Z x_1 x_2)\\
    %       &= (X x_1 (X x_1 (\pi_1 x_2)), Y (s^{-1} (x_1, (X x_1 (\pi_1 x_2)))) (Y (s^{-1} (x_1, (\pi_1 x_2))) (\pi_2 x_2)))\\
    %       &= (X x_1 (\pi_1 x_2), Y (s^{-1} (x_1, \pi_1 x_2)) (\pi_2 x_2))\\
    %       &= Z x_1 x_2.
    %     \end{align*}
    %   \item $ u $ is a morphism
    %     \begin{align*}
    %       \sum_A Z (u (\sum_B Y x_1))
    %       &= \sum_A Z (u (B (\pi_1 x_1), Y (\pi_1 x_1) (\pi_2 x_1)))\\
    %       &= \sum_A Z (\pi_1 (s (\pi_1 x_1)), (\pi_2 (s (\pi_1 x_1)), Y (\pi_1 x_1) (\pi_2 x_1)))\\
    %       &= (A (\pi_1 (s (\pi_1 x_1))), (X (\pi_1 (s (\pi_1 x_1))) ((\pi_2 (s (\pi_1 x_1)))), Y (\pi_1 x_1) (\pi_2 x_1)))\\
    %       &= u x_1.
    %     \end{align*}
    %   \item $ u^{-1} $ is a morphism
    %     \begin{align*}
    %       \sum_B Y (u^{-1} (\sum_A Z x_1))
    %       &= \sum_B Y (u^{-1} (A (\pi_1 x_1), (X (\pi_1 x_1) (\pi_1 (\pi_2 x_1)), Y (s^{-1} ((\pi_1 x_1), \pi_1 (\pi_2 x_1))) (\pi_2 (\pi_2 x_1)))))\\
    %       &= \sum_B Y (s^{-1}(\pi_1 x_1, \pi_1 (\pi_2 x_1)), Y (s^{-1} (\pi_1 x_1, \pi_1 (\pi_2 x_1))) (\pi_2 (\pi_2 x_1)))\\
    %       &= (s^{-1}(\pi_1 x_1, \pi_1 (\pi_2 x_1)), Y (s^{-1} (\pi_1 x_1, \pi_1 (\pi_2 x_1))) (\pi_2 (\pi_2 x_1)))\\
    %       &= u^{-1} x_1
    %     \end{align*}
    %   \item $ u \circ u^{-1} = \id{\sum_A Z} $
    %     \begin{align*}
    %       u(u^{-1} x_1)
    %       &= u(s^{-1} (\pi_1 x_1, \pi_1 (\pi_2 x_1)), Y (s^{-1} (\pi_1 x_1, \pi_1 (\pi_2 x_1))) (\pi_2 (\pi_2 x_1)))\\
    %       &= (A (\pi_1 x_1), (X (\pi_1 x_1) (\pi_1 (\pi_2 x_1)), Y (s^{-1} (\pi_1 x_1, \pi_1 (\pi_2 x_1))) (\pi_2 (\pi_2 x_1))))\\
    %       &= \sum_A Z x_1
    %     \end{align*}
    %   \item $ u^{-1} \circ u = \id{\sum_B Y} $.
    %     \begin{align*}
    %       u^{-1} (u x_1)
    %       &= u^{-1}(\pi_1 (s (\pi_1 x_1)), (\pi_2 (s (\pi_1 x_1)), Y (\pi_1 x_1) (\pi_2 x_1)))\\
    %       &= (B (\pi_1 x_1), Y (\pi_1 x_1) (\pi_2 x_1))
    %       &= \sum_B Y x_1.
    %     \end{align*}
    %   \item $ p_Z \circ u = g \circ p_Y $.
    %     \begin{align*}
    %       p_Z (u x_1)
    %       &= p_Z (\pi_1 (s (\pi_1 x_1)), (\pi_2 (s (\pi_1 x_1)), Y (\pi_1 x_1) (\pi_2 x_1)))\\
    %       &= A (\pi_1 (s (\pi_1 x_1)))\\
    %       &= A (\pi_1 (s (B (\pi_1 x_1))))\\
    %       &= p_X (s (p_Y x_1))\\
    %       g (p_Y x_1).
    %     \end{align*}
    % \end{itemize}
  \item Let $ B \to I $ be a terminal projection. Consider $ Y = (\lambda x_1, B) : \R^I $. We have
    \[ \sum_I Y = \lambda x_1, ((\lambda x_2, x_2), B (\pi_2 x_1)) = \langle I \circ \pi_1, B \circ \pi_2 \rangle = I \times B, \]
    which is isomorphic to $ B $.
\end{enumerate}

\begin{remark}
  There is an awful lot of properties to verify here (e.g. that some terms are elements of some $ \R^A $, that others are morphisms in some $ \R(\sum_A X, \sum_B Y) $, that some diagrams commute), but most of it boils down to writing down the equations that should hold, reducing them via $ \beta $-equality, and then using the facts that objects $ A: \R $ are idempotent, that morphisms $ f: \R(A, B) $ equal $ B \circ f \circ A $ and that objects $ X: \R^A $ satisfy $ X \circ A = X $ and $ X a (X a x) = X a x $ for all $ a $ and $ x $. Note that for a morphism $ f: \sum_A X \to B $,
  \[ f(A x_1, x_2) = f(x_1, x_2) = f(x_1, X x_1 x_2), \]
  so $ f $ `absorbs' such instances of $ A $ and $ X $, so to speak.
\end{remark}

\begin{remark}
  To talk about `relatively cartesian closed', we need a pullback functor $ \alpha^* : (\R \downarrow_D A) \to (\R \downarrow_D B) $ for all (display maps) $ \alpha: B \to A $. However, as remarked before, since the definition of display maps involves a propositional truncation, we only have mere existence of pullbacks, and to pass from the statement ``for all $ f $, there exists a pullback $ \alpha^* f $'' to the statement ``there exists a function that sends every morphism $ f : (\R \downarrow_D A) $ to its pullback $ \alpha^* f : (\R \downarrow_D B) $'', we need to assume the axiom of choice.

  However, note that we have a weak equivalence between strict categories (categories in which the type of objects is a homotopy set) $ \sum_A: \R^A \xrightarrow \sim (\R \downarrow_D A) $. If we assume the axiom of choice, $ \sum_A $ becomes an equivalence of categories (\cite{univalent-categories}, introduction, page 2 \TODO: maybe find a better reference for this) and then our pullback functor is given by
  \[ \sum_A^{-1} \bullet (\alpha \cdot -) \bullet \sum_B, \]
  where $ (\alpha \cdot -): \R^A \to \R^B $ denotes the functor given by precomposition with $ \alpha $.
\end{remark}

This brings us to the main theorem of this section (\cite{taylor}, 5.1.8).
\begin{theorem}
  If we assume the axiom of choice, $ \R $ is cartesian closed, relative to the given class of display maps.
\end{theorem}
\begin{proof}
  Let $ \alpha: B \to A $ be a display map. We have mere existence of some $ X: \R^A $ and an isomorphism $ g: (X, \alpha) \xrightarrow \sim (\sum B, p_X) $. We need to show that there is a right adjoint to the pullback functor $ \alpha^* $. Since under assumption of the axiom of choice, $ \alpha^* $ is defined as a composition of a precomposition functor with two equivalences of categories, this is equivalent to showing that there is a right adjoint to the precomposition functor $ (\alpha \cdot -): \R^A \to \R^B $ (note that $ \alpha \cdot - $ sends $ f $ to $ f \circ \alpha $).

  Now, intuitively, any $ Y: \R^B $ denotes an indexed family $ ((Y (a, b))_{b: X a})_{a: A} $. We want the right adjoint $ \alpha_* Y $ to be the indexed family of dependent products $ (\prod_{b: B_a} Y (a, b))_a $. An element $ f $ of the dependent product $ \alpha_* Y a $ is then a function from $ X a $, that satisfies $ f b : Y (a, b) $ for all $ b : X a $. Therefore, for all $ a : A $ and all $ f : L_0 $, we want $ (\alpha_* Y a) f = f $ to mean ``$ f \circ X a = f $ and, $ f b : Y (a, b) $ for all $ b: X a $''. We encode these two parts as
  \[ \lambda x_1, x_1 \circ X a \quad \text{and} \quad \lambda x_1 x_2, Y (g^{-1} (a, x_2)) (x_1 x_2). \]
  It turns out that these are idempotents and they commute, so we can compose them into one object
  \[ \alpha_* Y a = \lambda x_1 x_2, Y (g^{-1} (a, x_2)) (x_1 (X a x_2)) : \R \]
  and we define the combinator
  \[ \alpha_* = \lambda x_1 x_2 x_3 x_4, x_1 (g^{-1} (x_2, x_4)) (x_3 (X x_2 x_4)). \]
  Now, applying $ \alpha_* $ to both objects and morphisms in $ \R^A $ gives a functor $ \alpha_* : \R^B \to \R^A $.

  Note that for all $ Y : \R^B $ and all $ b $, we have a morphism $ (\lambda x_1, x_1 (\pi_2 (g b))) : \R(\alpha_* Y (\alpha b), Y b) $. Making this parametric in $ b $ gives us a counit
  \[ \epsilon_Y = \lambda x_1 x_2, Y x_1 (x_2 (\pi_2 (g x_1))) : \R^B((\alpha_* Y) \circ \alpha, Y). \]

  % First of all, $ \epsilon_Y \circ B = \epsilon_Y $, also
  % \begin{align*}
  %   (Y x_1 \circ \epsilon_Y x_1 \circ (\alpha_* Y \circ \alpha) x_1) x_2
  %   &= Y x_1 (\epsilon_Y x_1 (\alpha_* Y (\alpha x_1) x_2))\\
  %   &= Y x_1 ((\lambda f, Y x_1 (f (X (\alpha x_1) (\pi_2 (g x_1))))) (\lambda x_3, Y (g^{-1} (\alpha x_1, x_3)) (x_2 (X (\alpha x_1) x_3))))\\
  %   &= Y x_1 (((\lambda x_3, Y (g^{-1} (\alpha x_1, x_3)) (x_2 (X (\alpha x_1) x_3)))) (X (\alpha x_1) (\pi_2 (g x_1))))\\
  %   &= Y x_1 (Y (g^{-1} (\alpha x_1, (\pi_2 (g x_1)))) (x_2 (X (\alpha x_1) (X (\alpha x_1) (\pi_2 (g x_1))))))\\
  %   &= Y x_1 (Y x_1 (x_2 (X (\alpha x_1) (X (\alpha x_1) (\pi_2 (g x_1))))))\\
  %   &= Y x_1 (x_2 (X (\alpha x_1) (\pi_2 (g x_1))))\\
  %   &= \epsilon_Y x_1 x_2.
  % \end{align*}

  To show that $ (\alpha \cdot -) \dashv \alpha_* $, we need to show that for all $ Y : \R^B $, $ (\alpha_* Y, \epsilon_Y) $ is a universal arrow from $ (\alpha \cdot -) $ to $ Y $. Recall the following diagram:
  \begin{center}
    \begin{tikzcd}
      Z \circ \alpha \arrow[rd, "f"'] \arrow[r, "{\hat f \circ \alpha}", dashed] & (\alpha_* Y) \circ \alpha \arrow[d, "{\epsilon_Y}"]\\
      & Y
    \end{tikzcd}
  \end{center}
  Now, suppose that we have some $ Z : \R^A $ and some $ f: \R^B(Z \circ \alpha, Y) $. We define
  \[ \hat f = \lambda x_1 x_2 x_3, f(g^{-1}(x_1, x_3)) (Z x_1 x_2): \R^A(Z, \alpha_* Y) \]
  and we have $ ((\hat f) \circ \alpha) \cdot \epsilon_Y = f $.
  % \begin{align*}
  %   (((\alpha \cdot -) \hat f) \cdot \epsilon_Y) b z
  %   &= \epsilon_Y b ((\hat f (\alpha b)) z)\\
  %   &= \epsilon_Y b (\lambda x_3, f (g^{-1} ((\alpha b), x_3)) (Z (\alpha b) z))\\
  %   &= Y b ((\lambda x_3, f (g^{-1} ((\alpha b), x_3)) (Z (\alpha b) z)) (\pi_2 (g b)))\\
  %   &= Y b (f (g^{-1} ((\alpha b), \pi_2 (g b))) (Z (\alpha b) z))\\
  %   &= Y b (f (g^{-1} (g b)) (Z (\alpha b) z))\\
  %   &= f b z.
  % \end{align*}
  Now, suppose that we have some (other) $ \hat f^\prime : \R^A(Z, \alpha_*(Y)) $ such that $ (\hat f^\prime \circ \alpha) \cdot \epsilon_Y = f $. Then substituting $ (\hat f^\prime \circ \alpha) \cdot \epsilon_Y $ for $ f $ in $ \hat f $ yields
  \[ \hat f = \lambda x_1, (\alpha_* Y x_1) \circ (\hat f^\prime x_1) = \hat f^\prime, \]
  so $ \hat f $ is unique and $ (\alpha_* Y, \epsilon_Y) $ is a universal arrow, which concludes the proof that $ (\alpha \cdot -) \dashv \alpha_* $ and we see that $ \R $ is cartesian closed relative to the given class of display maps.
  % \begin{align*}
  %   \hat f
  %   &= \lambda x_1 x_2 x_3, f (g^{-1} (x_1, x_3))(Z x_1 x_2)\\
  %   &= \lambda x_1 x_2 x_3, ((\epsilon_Y (g^{-1} (x_1, x_3))) \circ ((\hat f^\prime \circ \alpha) (g^{-1} (x_1, x_3)))) (Z x_1 x_2)\\
  %   &= \lambda x_1 x_2 x_3, (\epsilon_Y (g^{-1} (x_1, x_3))) (\hat f^\prime (\alpha (g^{-1} (x_1, x_3))) (Z x_1 x_2))\\
  %   &= \lambda x_1 x_2 x_3, (\epsilon_Y (g^{-1} (x_1, x_3))) (\hat f^\prime x_1 x_2)\\
  %   &= \lambda x_1 x_2 x_3, Y (g^{-1} (x_1, x_3)) (\hat f^\prime x_1 x_2 (\pi_2 (g (g^{-1} (x_1, x_3)))))\\
  %   &= \lambda x_1 x_2 x_3, Y (g^{-1} (x_1, x_3)) (\hat f^\prime x_1 x_2 (X x_1 x_3))\\
  %   &= \lambda x_1 x_2, \alpha_* Y x_1 (\hat f^\prime x_1 (Z x_1 x_2))\\
  %   &= \hat f^\prime
  % \end{align*}
\end{proof}

\begin{remark}
  Recall that in the definition of $ \alpha_* $, we composed commuting idempotents
  \[ \lambda x_1 x_2, x_1 (X a x_2) \quad \text{and} \quad \lambda x_1 x_2, Y (a, x_2) (x_1 x_2). \]
  In his PhD thesis, Taylor instead composes the idempotents
  \[ \lambda x_1, x_1 (X a x_2) \quad \text{and} \quad \lambda x_1 x_2, Y x_2 (x_1 x_2). \]
  Note that in the first term, $ x_2 $ plays the role of an element of $ X a $, whereas in the second term, it plays the role of an element of $ B $. Of course, if we worked in $ \SET $, we would indeed have $ X a \subseteq \bigsqcup_{a : A} X_a \cong B $. However, in $ \R $, the `terms' of $ B \cong \sum_A X $ look like pairs $ (a, x) $ with $ a : A $ and $ x : X a $, so we cannot consider terms of $ X a $ to be terms of $ B $.

  Therefore, the idempotents that he uses do not commute, and the resulting term
  \[ \lambda x_1 x_2, Y (B x_2) (x_1 (X a x_2)) \]
  (notice the redundant usage of $ B $) is not idempotent.
\end{remark}
